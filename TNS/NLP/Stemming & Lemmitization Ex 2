{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMW6vZbs6KyXHGHWtwkdakv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aY75PPoW6dps","executionInfo":{"status":"ok","timestamp":1757865050710,"user_tz":-330,"elapsed":4891,"user":{"displayName":"Nayna Sagar Dahatonde","userId":"08351810259517213934"}},"outputId":"748564e4-96bf-4f1c-a479-a0bf62ea3250"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Original Text:\n","The cats are running and studies were better than studying.\n","---------------------------------------------------\n","1. Tokenization:\n","['The', 'cats', 'are', 'running', 'and', 'studies', 'were', 'better', 'than', 'studying', '.']\n","---------------------------------------------------\n","2. Stemming:\n","['the', 'cat', 'are', 'run', 'and', 'studi', 'were', 'better', 'than', 'studi', '.']\n","---------------------------------------------------\n","3. Lemmatization (WordNet):\n","['The', 'cat', 'are', 'running', 'and', 'study', 'were', 'better', 'than', 'studying', '.']\n","---------------------------------------------------\n","3. Lemmatization (spaCy):\n","['the', 'cat', 'be', 'run', 'and', 'study', 'be', 'well', 'than', 'study', '.']\n"]}],"source":["#!pip install nltk\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","import spacy\n","\n","# Download required data (run once)\n","nltk.download('punkt')\n","nltk.download('punkt_tab')   # ðŸ‘ˆ NEW fix\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","\n","# Load English model for lemmatization using spaCy\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Sample text\n","text = \"The cats are running and studies were better than studying.\"\n","\n","print(\"Original Text:\")\n","print(text)\n","print(\"---------------------------------------------------\")\n","\n","# 1. Tokenization\n","tokens = word_tokenize(text)\n","print(\"1. Tokenization:\")\n","print(tokens)\n","print(\"---------------------------------------------------\")\n","\n","# 2. Stemming\n","stemmer = PorterStemmer()\n","stems = [stemmer.stem(word) for word in tokens]\n","print(\"2. Stemming:\")\n","print(stems)\n","print(\"---------------------------------------------------\")\n","\n","# 3. Lemmatization\n","lemmatizer = WordNetLemmatizer()\n","lemmas = [lemmatizer.lemmatize(word) for word in tokens]\n","print(\"3. Lemmatization (WordNet):\")\n","print(lemmas)\n","print(\"---------------------------------------------------\")\n","\n","# Alternative Lemmatization with spaCy (better results)\n","doc = nlp(text)\n","spacy_lemmas = [token.lemma_ for token in doc]\n","print(\"3. Lemmatization (spaCy):\")\n","print(spacy_lemmas)\n"]}]}